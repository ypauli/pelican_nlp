# Configuration file: variable parameters
# =======================================
input_file: "text" #or 'audio'

PATH_TO_PROJECT_FOLDER: "/home/ubuntu/PELICAN/pelican/simulation/simu_output" # Set default to home directory, e.g., '/home/usr/...'
language: "german" # Possibly add options for German and English
numberOfSubjects: null # Specify number of subjects; if 'null', number of subjects is automatically detected
multipleSessions: true # Set to True if multiple sessions per subject

recompute_everything: true #If set to 'false' pelican will try to reuse previously computed results stored on your drive

has_multiple_sections: true #evaluated independently
section_identification: "New Prompt: " #e.g. "Section:", 'null' if file does not have multiple sections, use pattern that is unlikely to appear in rest of transcript
number_of_sections: null #if 'null' number of sections automatically detected, however, specifying number recommended if known.

task_names:
  - "text_generation" # Give names of tasks used for creation of the text file (e.g., ['fluency', 'interview'])
corpus_names:
  - "group_a"
  - "group_b" # Names of individual categories to group together

extract_logits: null
extract_embeddings: true

tokenization: "wordLevel" # Options: 'characterLevel', 'subWordLevel'

# Options for extract_logits
chunk_size: null
overlap_size: null

# Options for extract_embeddings
window_sizes: [2]
metric_function: cosine_similarity
aggregation_functions: mean_of_means

cleaning_options:
  general_cleaning: true # General cleaning options used for most text preprocessing, default: True.
  remove_punctuation: true
  lowercase: true
  remove_brackets_and_bracketcontent: true

general_cleaning_options:
  strip_whitespace: true
  merge_multiple_whitespaces: true
  remove_whitespace_before_punctuation: true
  merge_newline_characters: true
  remove_backslashes: true

tokenization_options_logits:
  method: "model_instance" # Options: model_instance, regex, nltk, etc.
  model_name: "DiscoResearch/Llama3-German-8B-32k" # Replace with your model instance name

tokenization_options_embeddings:
  method: "whitespace"

normalization_options:
  method: "lemmatization" #Options: lemmatization or stemming
